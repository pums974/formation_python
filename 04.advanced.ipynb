{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avanced Python\n",
    "\n",
    "## Reminder\n",
    "- I/O\n",
    " - **Always** decode in input  \n",
    " - **Always** encode in output\n",
    "- modules : import involve execution! Use\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    ...\n",
    "```\n",
    "- Be carefull with shared references\n",
    "```python\n",
    "a is b # a and b are references to the same object\n",
    "```\n",
    "\n",
    "Tips\n",
    "--------\n",
    "- On all your script : \n",
    "  - shebang ``` #!/usr/bin/env python3 ```\n",
    "  - encoding ``` # -*- coding: utf-8 -*- ```\n",
    "- underscore have a lot of different meanings\n",
    "  - separator in number ``` 10_000 ``` (only python 3.6)\n",
    "  - last result in the interpreter ``` _ ```\n",
    "  - I don't care ``` _ = f() ``` (dangerous with internationnaization)\n",
    "  - weakly private ``` _something ``` (won't be imported with ```import *```)\n",
    "  - avoid conflict ``` list_ ```\n",
    "  - more private (mangled) ```__stuff```\n",
    "  - magic methods (also mangled) ``` __init__```\n",
    "  - for internationnalization ```_()```\n",
    "- unpacking dans les boucles \n",
    "  - zip:\n",
    "```python\n",
    "for name, surname in zip(names, surnames):\n",
    "    ...\n",
    "```\n",
    "  - enumerate\n",
    "```python\n",
    "for index, prime in enumerate(primes):\n",
    "    ...\n",
    "```\n",
    "- False tests :\n",
    "```python\n",
    "False, 0, None, __nonzero__(), __len__()\n",
    "```\n",
    " \n",
    " \n",
    "- **never** use a mutable optionnal arg\n",
    "- use a shallow copy to modify a list in a loop (or be very carefull)\n",
    "- use exceptions\n",
    "    - try is very fast but except is very slow\n",
    "    - nice way to get out of multiples loops/functions at the same time\n",
    "    - Allows you to be sure that an error had been taken care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong(a_list=[]):  # never use a mutable optionnal argument\n",
    "    a_list.append(1)\n",
    "    return a_list\n",
    "print(wrong())\n",
    "print(wrong())\n",
    "print(wrong([2]))\n",
    "print(wrong())\n",
    "\n",
    "def good(a_list=None):\n",
    "    if a_list is None:\n",
    "        a_list = []\n",
    "    a_list.append(1)\n",
    "    return a_list\n",
    "print(good())\n",
    "print(good())\n",
    "print(good([2]))\n",
    "print(good())\n",
    "\n",
    "print()\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "def good(my_set):\n",
    "    for value in copy(my_set):\n",
    "        if 'bert' in value:\n",
    "            my_set.remove(value)\n",
    "    return(my_set)\n",
    "            \n",
    "def wrong(my_set):\n",
    "    for value in my_set:\n",
    "        if 'bert' in value:\n",
    "            my_set.remove(value)\n",
    "    return(my_set)\n",
    "\n",
    "print(\"list  ok \", good([\"einstein\", \"albert\", \"bert\", \"curie\"]))\n",
    "print(\"set   ok \", good({\"einstein\", \"albert\", \"bert\", \"curie\"}))\n",
    "\n",
    "print(\"list Nok \", wrong([\"einstein\", \"albert\", \"bert\", \"curie\"]))\n",
    "\n",
    "try:\n",
    "    print(\"set  Nok \", wrong({\"einstein\", \"albert\", \"bert\", \"curie\"}))\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print()\n",
    "    print(\"Oups, something went wrong:\")\n",
    "    print(e)\n",
    "    print(\"Continuing anyway\")\n",
    "    print()\n",
    "    \n",
    "print(\"set  Nok \", wrong({\"einstein\", \"albert\", \"bert\", \"curie\"}))\n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use decorator\n",
    "  - debugging, timing, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def PrintAppel(f):\n",
    "    def before_f():\n",
    "        new_f.NbAppels += 1\n",
    "        print(\"Entering {}\".format(f.__name__))\n",
    "        \n",
    "    def after_f():\n",
    "        print(\"Exiting {}\".format(f.__name__))\n",
    "        print(\"This was the call nÂ° {}\".format(new_f.NbAppels))\n",
    "    \n",
    "    @wraps(f)\n",
    "    def new_f(*args, **xargs):\n",
    "        before_f()\n",
    "        res = f(*args, **xargs)\n",
    "        after_f()\n",
    "        return res\n",
    "    \n",
    "    new_f.NbAppels = 0\n",
    "    \n",
    "    return new_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@PrintAppel\n",
    "def a_functon(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_functon(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make use of classes In order to isolate your work (and your bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class egg(object):                              # All objects derived from the same object \"object\"\n",
    "    \"\"\" Full exemple of a class in python \"\"\"\n",
    "    total_number = 0                            # shared attribut between all instances **DANGER** ! \n",
    "  \n",
    "    def __init__(self, number=1):               # constructor\n",
    "        \"\"\" constructor from number \"\"\"\n",
    "        self.number = number                    # Good way of defining attributes\n",
    "        egg.total_number += number\n",
    "    \n",
    "    @classmethod\n",
    "    def from_recipe(cls, recipe):               # Alternative constructor\n",
    "        \"\"\" constructor from recipe \"\"\"\n",
    "        return cls(recipe[\"oeufs\"])\n",
    "    \n",
    "    def __del__(self):                          # destructor (rare)\n",
    "        \"\"\" destructor \"\"\"\n",
    "        egg.total_number -= self.number\n",
    "\n",
    "    def __str__(self):                          # convert your object into printable string\n",
    "        \"\"\" egg to str convertor \"\"\"\n",
    "        return \"On a total of {} eggs, I own {}\".format(egg.total_number, self.number)\n",
    "        \n",
    "    def how_many(self):                         # a function of the instance\n",
    "        \"\"\" Return the current number of eggs in the recipe \"\"\"\n",
    "        return self.number\n",
    "\n",
    "    @staticmethod\n",
    "    def how_many_egg():                          # a function on the class (rare)\n",
    "        \"\"\" Return the total number of eggs for all recipes \"\"\"\n",
    "        return egg.total_number\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    fried_egg = egg()\n",
    "    omelette = egg(3)\n",
    "    recipe_pancake = {\"oeufs\":2, \"lait\":0.5, \"farine\":300}\n",
    "    pancake = egg.from_recipe(recipe_pancake)\n",
    "    print(\"Fried egg    : \", fried_egg)\n",
    "    print(\"Omelette     : \", omelette)\n",
    "    print(\"Pancake      : \", pancake)\n",
    "    print()\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"egg\",\n",
    "                                       \"NaN\",\n",
    "                                       egg.how_many_egg()))\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"fried_egg\",\n",
    "                                       fried_egg.how_many(),\n",
    "                                       fried_egg.how_many_egg()))\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"omelette\",\n",
    "                                       omelette.how_many(), omelette.how_many_egg()))\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"pancake\",\n",
    "                                       pancake.how_many(),\n",
    "                                       pancake.how_many_egg()))\n",
    "    print()\n",
    "    del omelette\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"egg\",\n",
    "                                       \"NaN\",\n",
    "                                       egg.how_many_egg()))\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"fried_egg\",\n",
    "                                       fried_egg.how_many(),\n",
    "                                       fried_egg.how_many_egg()))\n",
    "    print(\"{:<12} : {:>5} | {}\".format(\"pancake\",\n",
    "                                       pancake.how_many(),\n",
    "                                       pancake.how_many_egg()))\n",
    "    del fried_egg\n",
    "    del pancake\n",
    "\n",
    "    print()\n",
    "    help(egg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For launching external program :\n",
    "  - ```subprocess.check_call([\"cmd\", \"arg1\", \"arg2\"])``` If you don't care about the output of the program\n",
    "  - ```data = subprocess.check_output([\"cmd\", \"arg1\", \"arg2\"])``` otherwise (remember to decode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "data = subprocess.check_output([\"ls\", \"-l\", \"--color\"]).decode('utf-8')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packaging\n",
    "---------\n",
    "- respect PEP (not only for prettyness)\n",
    "- docstring (auto-documentation)\n",
    "  - All fonctions\n",
    "  - All classes\n",
    "  - All modules (```__init__.py```)\n",
    "  - All files\n",
    "- type hinting (that's new)\n",
    "  - Almost totally ignored during execution\n",
    "  - mypy (and more and more IDE) are capable of checking consistency\n",
    "  - The typing module allows you to define complex types\n",
    "  - More and more package are complient with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting(name: str) -> str:\n",
    "    var = \"Hello\"  # type: str\n",
    "    # python 3.7 : var = \"Hello\" : str\n",
    "    \n",
    "    return var + \" \" + name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytest  (unit-testing)\n",
    "  - auto discovery (use tests folders, test_truc function, and TestMachin classes)\n",
    "  - allow parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY for ipython\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "__file__ = '04.advanced.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -qq\n",
    "#this was only for ipython\n",
    "\n",
    "def test_sorted():\n",
    "    assert sorted([5, 1, 4, 2, 3]) == [1, 2, 3, 4, 5]\n",
    "    \n",
    "# as does parametrize\n",
    "@pytest.mark.parametrize('input, expected', [\n",
    "                                            ([2, 1], [1, 2]),\n",
    "                                            ('zasdqw', list('adqswz')),\n",
    "                                            ]\n",
    "                         )\n",
    "def test_exemples(input, expected):\n",
    "    actual = sorted(input)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gettext (auto-internationnalization) ?\n",
    "- argparse\n",
    "- configParser\n",
    "- logging\n",
    "  - print -> go to console (for ordinary usage)\n",
    "  - warning.warn -> go to console (usually once : for signaling a something the user should fix)\n",
    "  - logging.level -> go anywhere you want (for detailled output and/or diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "\n",
    "def prepare_logging():\n",
    "    \"\"\"\n",
    "    Prepare all logging facilities\n",
    "    \n",
    "    This should be done in a separate module\n",
    "    \"\"\"\n",
    "\n",
    "    # if not already done, initialize logging facilities\n",
    "    logging.basicConfig()\n",
    "\n",
    "    # create a logger for the current module\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    ## ONLY FOR IPYTHON\n",
    "    # clean logger (ipython + multiple call)\n",
    "    from copy import copy\n",
    "    for handler in copy(logger.handlers):\n",
    "        logger.removeHandler(handler)\n",
    "    # Do not propagate message to ipython (or else thy will be printed twice)\n",
    "    logger.propagate=False\n",
    "    ## ONLY FOR IPYTHON\n",
    "\n",
    "\n",
    "    # optionnal : change format of the log\n",
    "    logFormatter = logging.Formatter(\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\")\n",
    "\n",
    "    # optionnal : create a handler for file output\n",
    "    fileHandler = logging.FileHandler(\"{logPath}/{fileName}.log\".format(logPath=\".\", fileName=\"test\"))\n",
    "    # optionnal : create a handler for console output\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "\n",
    "    # optionnal : Apply formatter to both handles\n",
    "    fileHandler.setFormatter(logFormatter)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "\n",
    "    # optionnal : attach handler to the logger\n",
    "    logger.addHandler(fileHandler)\n",
    "    logger.addHandler(consoleHandler)\n",
    "\n",
    "    # what severity to log (default is NOTSET, i.e. all)\n",
    "    logger.setLevel(logging.DEBUG)            # ALL\n",
    "    fileHandler.setLevel(logging.INFO)        # NO DEBUG\n",
    "    consoleHandler.setLevel(logging.WARNING)  # ONLY WARNING AND ERRORS\n",
    "\n",
    "    return logger\n",
    "    \n",
    "\n",
    "def egg():\n",
    "    warnings.warn(\"A warning only once\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger = prepare_logging()\n",
    "\n",
    "    egg()\n",
    "\n",
    "    logger.info('Start reading database')\n",
    "\n",
    "    records = {'john': 55, 'tom': 66}\n",
    "\n",
    "    logger.debug('Records: {}'.format(records))\n",
    "    logger.info('Updating records ...')\n",
    "    logger.warning(\"There is only 2 record !\")\n",
    "    logger.info('Saving records ...')\n",
    "    logger.error(\"Something happend, impossible to save the records\")\n",
    "    logger.info('Restoring records ...')\n",
    "    logger.critical(\"Database corrupted !\")\n",
    "    logger.info('End of program')\n",
    "\n",
    "    egg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Performance\n",
    "\n",
    "- profiling : Only optimize the bottlenecks !\n",
    "  - timeit (for small snippets of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [1 + i for i in range(1,10000)]\n",
    "%timeit [1 * i for i in range(1,10000)]\n",
    "%timeit [1 / i for i in range(1,10000)]\n",
    "%timeit [1 // i for i in range(1,10000)]\n",
    "\n",
    "%timeit [1. + float(i) for i in range(1,10000)]\n",
    "%timeit [1. * float(i) for i in range(1,10000)]\n",
    "%timeit [1. / float(i) for i in range(1,10000)]\n",
    "%timeit [1. // float(i) for i in range(1,10000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - cProfile (for real code)  \n",
    "   ```python3 -m cProfile -o profile.pstats script.py```  \n",
    "   ```gprof2dot -f pstats profile.pstats | dot -Tpng -o profile.png```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cProfile\n",
    "import re\n",
    "\n",
    "def function2(array):\n",
    "    for i in range(500):\n",
    "        array += 3\n",
    "        array = array * 2\n",
    "    return array\n",
    "\n",
    "def function1():\n",
    "    array = np.random.randint(500000, size=5000000)\n",
    "    array = function2(array)\n",
    "    return sorted(array)\n",
    "\n",
    "cProfile.run('function1()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/profile.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in sequential\n",
    "    - small is beautifull (PEP 20)\n",
    "    - inline manually\n",
    "    - local is faster than global (and avoid dots)\n",
    "    - choose the right data structure / algorithm\n",
    "    - prefere numpy based array\n",
    "    - avoid loops (vectorization using slice)\n",
    "    - avoid copy of array\n",
    "    - changing size of an array\n",
    "    - use the out argument in numpy\n",
    "    - IO cost a lot (avoid reading and writing into files)\n",
    "- compiler\n",
    "  - numexpr (only small expression)\n",
    "  - f2py\n",
    "    - included with numpy\n",
    "    - compilation must be done separately\n",
    "    - be carefull to the memory ordering\n",
    "  - cython\n",
    "  - numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python code (reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sum as npsum\n",
    "\n",
    "def pyfunction1(a, b):\n",
    "    return a * b - 4.1 * a > 2.5 * b\n",
    "\n",
    "def pyfunction2(a, b):\n",
    "    return np.sin(a) + np.arcsinh(a / b)\n",
    "\n",
    "def convolve_python(f, g):\n",
    "    # f is an image and is indexed by (v, w)\n",
    "    # g is a filter kernel and is indexed by (s, t),\n",
    "    #   it needs odd dimensions\n",
    "    # h is the output image and is indexed by (x, y),\n",
    "\n",
    "    if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1:\n",
    "        raise ValueError(\"Only odd dimensions on filter supported\")\n",
    "        \n",
    "    # smid and tmid are number of pixels between the center pixel\n",
    "    # and the edge, ie for a 5x5 filter they will be 2.\n",
    "    vmax = f.shape[0]\n",
    "    wmax = f.shape[1]\n",
    "    smax = g.shape[0]\n",
    "    tmax = g.shape[1]\n",
    "    \n",
    "    smid = smax // 2\n",
    "    tmid = tmax // 2\n",
    "\n",
    "    # Allocate result image.\n",
    "    h = np.zeros_like(f)\n",
    "    \n",
    "    # Do convolution\n",
    "    for x in range(smid, vmax - smid):\n",
    "        for y in range(tmid, wmax - tmid):\n",
    "            # Calculate pixel value for h at (x,y). Sum one component\n",
    "            # for each pixel (s, t) of the filter g.\n",
    "            \n",
    "            #value = 0\n",
    "            #for s in range(smax):\n",
    "            #    for t in range(tmax):\n",
    "            #        v = x - smid + s\n",
    "            #        w = y - tmid + t\n",
    "            #        value += g[s, t] * f[v, w]\n",
    "            #h[x, y] = value\n",
    "            \n",
    "            # exploit vectorization\n",
    "            \n",
    "            v1 = x - smid\n",
    "            v2 = v1 + smax\n",
    "            w1 = y - tmid\n",
    "            w2 = w1 + tmax\n",
    "            h[x, y] = npsum(g * f[v1:v2, w1:w2])\n",
    "            \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(f, g):\n",
    "    return f.copy(), g.copy()\n",
    "\n",
    "def check(fun, data, ref=None, setup=nothing, timing=True):\n",
    "\n",
    "    print(\"Testing \", fun.__name__)\n",
    "    \n",
    "    f, g = setup(*data)\n",
    "\n",
    "    if ref is None:\n",
    "        res = fun(f, g)\n",
    "    else:\n",
    "        res = fun(f, g)\n",
    "        \n",
    "        if type(ref) is not type(res):\n",
    "            print(\"types are differents : \",type(ref), type(res))\n",
    "            return res\n",
    "        \n",
    "        if ref.dtype != res.dtype:\n",
    "            print(\"dtypes are differents : \",ref.dtype, res.dtype)\n",
    "            return res\n",
    "\n",
    "        if not np.array_equal(res, ref):\n",
    "            print(\"results are differents\")\n",
    "            print(\"  ref shape: \", ref.shape)\n",
    "            print(\"  res shape: \", res.shape)\n",
    "            print()\n",
    "            print(\"  ref\\n\", ref)\n",
    "            print(\"  res\\n\", res)\n",
    "            #print()\n",
    "            #print(\"  ref\\n\", ref[4:-4, 4:-4])\n",
    "            #print(\"  res\\n\", res[4:-4, 4:-4])\n",
    "            return res\n",
    "        \n",
    "    if timing:\n",
    "        %timeit fun(f, g)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "a = np.arange(1,1e6)\n",
    "b = np.arange(1,1e6)\n",
    "\n",
    "n = 4\n",
    "s = 2 * n + 1\n",
    "g = np.arange(s ** 2, dtype=np.int).reshape((s, s))\n",
    "\n",
    "N = 200\n",
    "small_f = np.arange(N * N, dtype=np.int).reshape((N, N))\n",
    "N = 2000\n",
    "large_f = np.arange(N * N, dtype=np.int).reshape((N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial result\n",
    "ref1 = check(pyfunction1, (a, b))\n",
    "ref2 = check(pyfunction2, (a, b))\n",
    "print()\n",
    "ref_small_convolve = check(convolve_python, (small_f, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can look at the bytecode (halfway to assembly)\n",
    "And use it to optimize some things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dis\n",
    "print(dis.code_info(pyfunction2))\n",
    "print(\"Code :\")\n",
    "dis.dis(pyfunction2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sin, arcsinh\n",
    "\n",
    "# We can avoid the step 0 and 12\n",
    "def pyfunction2_bis(a, b):\n",
    "    return sin(a) + arcsinh(a / b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dis\n",
    "print(dis.code_info(pyfunction2_bis))\n",
    "print(\"Code :\")\n",
    "dis.dis(pyfunction2_bis)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(pyfunction2_bis, (a, b), ref=ref2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When possible use already available function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "def scipy_convolve(f, g):\n",
    "    \n",
    "    vmax = f.shape[0]\n",
    "    wmax = f.shape[1]\n",
    "    \n",
    "    smax = g.shape[0]\n",
    "    tmax = g.shape[1]\n",
    "    \n",
    "    smid = smax // 2\n",
    "    tmid = tmax // 2\n",
    "    \n",
    "    h = np.zeros_like(f)\n",
    "    h[smid:vmax - smid, tmid:wmax - tmid] =  convolve2d(f, g, mode=\"valid\")\n",
    "\n",
    "    return h\n",
    "    \n",
    "def scipy_setup(f, g):\n",
    "    # for some reason, scipy take the filter in reverse...\n",
    "    gr = g[::-1,::-1]\n",
    "    return f.copy(), gr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(scipy_convolve, (small_f, g), ref=ref_small_convolve, setup=scipy_setup)\n",
    "ref_large_convolve = check(scipy_convolve, (large_f, g), setup=scipy_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numexpr allows compilation of very simple code\n",
    "And is multithreaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "def ne_function1(a, b):\n",
    "    return ne.evaluate('a * b - 4.1 * a > 2.5 * b')\n",
    "\n",
    "def ne_function2(a, b):\n",
    "    return ne.evaluate(\"sin(a) + arcsinh(a / b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(ne_function1, (a, b), ref=ref1)\n",
    "_ = check(ne_function2, (a, b), ref=ref2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba allows compilation of more complex code using only decorators\n",
    "And can parallelize part of your code  \n",
    "But it doesn't work everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=False, parallel=True)\n",
    "def nb_function1(a, b):\n",
    "    return a * b - 4.1 * a > 2.5 * b\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=False, parallel=True)\n",
    "def nb_function2(a, b):\n",
    "    return np.sin(a) + np.arcsinh(a / b)\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=False, parallel=True)\n",
    "def convolve_kernel(f, g):\n",
    "    # smid and tmid are number of pixels between the center pixel\n",
    "    # and the edge, ie for a 5x5 filter they will be 2.\n",
    "    vmax = f.shape[0]\n",
    "    wmax = f.shape[1]\n",
    "    smax = g.shape[0]\n",
    "    tmax = g.shape[1]\n",
    "    \n",
    "    smid = smax // 2\n",
    "    tmid = tmax // 2\n",
    "\n",
    "    # Allocate result image.\n",
    "    h = np.zeros_like(f)\n",
    "    \n",
    "    # Do convolution\n",
    "    for x in range(smid, vmax - smid):\n",
    "        for y in range(tmid, wmax - tmid):\n",
    "            # Calculate pixel value for h at (x,y). Sum one component\n",
    "            # for each pixel (s, t) of the filter g.\n",
    "            \n",
    "            value = 0\n",
    "            for s in range(smax):\n",
    "                for t in range(tmax):\n",
    "                    v = x - smid + s\n",
    "                    w = y - tmid + t\n",
    "                    value += g[s, t] * f[v, w]\n",
    "            h[x, y] = value\n",
    "            \n",
    "            #v1 = x - smid\n",
    "            #v2 = v1 + smax\n",
    "            #w1 = y - tmid\n",
    "            #w2 = w1 + tmax\n",
    "            #h[x, y] = np.sum(g * f[v1:v2, w1:w2])\n",
    "    return h\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=False, parallel=True)\n",
    "def convolve_numba(f, g):\n",
    "\n",
    "    if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1:\n",
    "        raise ValueError(\"Only odd dimensions on filter supported\")\n",
    "\n",
    "    return convolve_kernel(f, g)\n",
    "\n",
    "# Stencil contains implicit loops\n",
    "@nb.stencil(standard_indexing=(\"g\",),neighborhood=((-4, 4),(-4, 4)))\n",
    "def convolve_kernel1(f, g):\n",
    "\n",
    "    smax = g.shape[0]\n",
    "    tmax = g.shape[1]\n",
    "\n",
    "    smid = smax // 2\n",
    "    tmid = tmax // 2\n",
    "    \n",
    "    h = 0\n",
    "    for s in range(smax):\n",
    "        for t in range(tmax):\n",
    "            h += g[s, t] * f[s - smid, t - tmid]\n",
    "     \n",
    "    return h\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=False, parallel=True)\n",
    "def convolve_numba1(f, g):\n",
    "\n",
    "    if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1:\n",
    "        raise ValueError(\"Only odd dimensions on filter supported\")\n",
    "\n",
    "    return convolve_kernel1(f, g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be wompiled at first use\n",
    "tmpa = np.arange(1, 5)\n",
    "tmpb = np.arange(1, 5)\n",
    "nb_function1(tmpa, tmpb)\n",
    "nb_function2(tmpa, tmpb)\n",
    "N = 10\n",
    "tmpf = np.arange(N * N, dtype=np.int).reshape((N, N))\n",
    "_ = convolve_numba(tmpf, g)\n",
    "print(\"compilation OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(nb_function1, (a, b), ref=ref1)\n",
    "_ = check(nb_function2, (a, b), ref=ref2)\n",
    "print()\n",
    "_ = check(convolve_numba, (small_f, g), ref=ref_small_convolve)\n",
    "_ = check(convolve_numba, (large_f, g), ref=ref_large_convolve)\n",
    "print()\n",
    "_ = check(convolve_numba1, (small_f, g), ref=ref_small_convolve)\n",
    "_ = check(convolve_numba1, (large_f, g), ref=ref_large_convolve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython is the most efficient way to optimize your code\n",
    "But you have to:\n",
    "- type *every* variable\n",
    "- explicit all loops\n",
    "- parallelize manually\n",
    "- compile it separately (or use ipython magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --compile-args=-march=native --link-args=-fopenmp -a\n",
    "# cython: language_level=3\n",
    "# cython: initializedcheck=False\n",
    "# cython: binding=True\n",
    "# cython: nonecheck=False\n",
    "### cython: np_pythran=True\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libc.math cimport sin\n",
    "from libc.math cimport asinh\n",
    "from cython.parallel cimport parallel, prange\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "def cfunction1(double[::1] a, double[::1] b):\n",
    "    cdef long n = a.shape[0]\n",
    "\n",
    "    cdef long[:] res = np.empty([n], dtype=long)\n",
    "    \n",
    "    cdef Py_ssize_t i\n",
    "    for i in range(n):\n",
    "        res[i] = a[i] * b[i] - 4.1 * a[i] > 2.5 * b[i]\n",
    "    return res\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "def cfunction2(double[::1] a, double[::1] b):\n",
    "    cdef long n = a.shape[0]\n",
    "\n",
    "    cdef double[:] res = np.empty([n], dtype=np.double)\n",
    "    \n",
    "    cdef Py_ssize_t i\n",
    "    for i in range(n):\n",
    "        res[i] = sin(a[i]) + asinh(a[i] / b[i])\n",
    "    return res\n",
    "\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "def convolve_cython(long[:,::1] f, long[:,::1] g):\n",
    "    # f is an image and is indexed by (v, w)\n",
    "    # g is a filter kernel and is indexed by (s, t),\n",
    "    #   it needs odd dimensions\n",
    "    # h is the output image and is indexed by (x, y),\n",
    "    if g.shape[0] % 2 != 1 or g.shape[1] % 2 != 1:\n",
    "        raise ValueError(\"Only odd dimensions on filter supported\")\n",
    "\n",
    "    # smid and tmid are number of pixels between the center pixel\n",
    "    # and the edge, ie for a 5x5 filter they will be 2.\n",
    "    \n",
    "    cdef long vmax = f.shape[0]\n",
    "    cdef long wmax = f.shape[1]\n",
    "    cdef long smax = g.shape[0]\n",
    "    cdef long tmax = g.shape[1]\n",
    "    cdef long smid = smax // 2\n",
    "    cdef long tmid = tmax // 2\n",
    "    \n",
    "    # Allocate result image.\n",
    "    cdef long[:,::1] h = np.zeros([vmax, wmax], dtype=long)\n",
    "\n",
    "    cdef long value\n",
    "    cdef Py_ssize_t x, y, s, t, v, w\n",
    "\n",
    "    # Do convolution\n",
    "    for x in prange(smid, vmax - smid, nogil=True, num_threads=8):\n",
    "        for y in range(tmid, wmax - tmid):\n",
    "            # Calculate pixel value for h at (x,y). Sum one component\n",
    "            # for each pixel (s, t) of the filter g.\n",
    "\n",
    "            value = 0\n",
    "            for s in range(smax):\n",
    "                for t in range(tmax):\n",
    "                    v = x - smid + s\n",
    "                    w = y - tmid + t\n",
    "                    value = value + g[s, t] * f[v, w]\n",
    "            h[x, y] = value\n",
    "                \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cython_function1(a, b):\n",
    "    return np.asarray(cfunction1(a, b), dtype=bool)\n",
    "\n",
    "def cython_function2(a, b):\n",
    "    return np.asarray(cfunction2(a, b))\n",
    "\n",
    "def cython_convolve(f, g):\n",
    "    return np.asarray(convolve_cython(f, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(cython_function1, (a, b), ref=ref1)\n",
    "_ = check(cython_function2, (a, b), ref=ref2)\n",
    "print()\n",
    "_ = check(cython_convolve, (small_f, g), ref=ref_small_convolve)\n",
    "_ = check(cython_convolve, (large_f, g), ref=ref_large_convolve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortran through f2py is also very efficient\n",
    "But you have to\n",
    "- rewrite your code\n",
    "- compile it separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsource = \"\"\"\n",
    "    module fortranmodule\n",
    "    implicit none\n",
    "    contains\n",
    "    \n",
    "    subroutine function1(a, b, c, n)\n",
    "    implicit none\n",
    "    integer(kind=8), intent(in) :: n\n",
    "    double precision,intent(in) :: a(n)\n",
    "    double precision,intent(in) :: b(n)\n",
    "    \n",
    "    logical,intent(out)         :: c(n)\n",
    "\n",
    "    c = a * b - 4.1 * a > 2.5 * b\n",
    "\n",
    "    end subroutine function1\n",
    "    \n",
    "    subroutine function2(a, b, c, n)\n",
    "    implicit none\n",
    "    integer(kind=8), intent(in)  :: n\n",
    "    double precision,intent(in)  :: a(n)\n",
    "    double precision,intent(in)  :: b(n)\n",
    "    \n",
    "    double precision,intent(out) :: c(n)\n",
    "\n",
    "    c = sin(a) + asinh(a / b)\n",
    "\n",
    "    end subroutine function2\n",
    "    \n",
    "    \n",
    "    subroutine convolve_fortran(f, g, vmax, wmax, smax, tmax, h, err)\n",
    "    use OMP_LIB\n",
    "    implicit none\n",
    "    integer(kind=8),intent(in)  :: vmax,wmax,smax,tmax\n",
    "    integer(kind=8),intent(in)  :: f(vmax, wmax), g(smax, tmax)\n",
    "    \n",
    "    integer(kind=8),intent(out) :: h(vmax, wmax)\n",
    "    integer(kind=8),intent(out) :: err\n",
    "    \n",
    "    integer(kind=8) :: smid,tmid\n",
    "    !integer(kind=8) :: value\n",
    "    integer(kind=8) :: x, y\n",
    "    !integer(kind=8) :: v, w, s, t\n",
    "    integer(kind=8) :: v1,v2,w1,w2\n",
    "    \n",
    "    ! f is an image and is indexed by (v, w)\n",
    "    ! g is a filter kernel and is indexed by (s, t),\n",
    "    !   it needs odd dimensions\n",
    "    ! h is the output image and is indexed by (v, w),\n",
    "\n",
    "    err = 0\n",
    "    if (modulo(smax, 2) /= 1 .or. modulo(tmax, 2) /= 1) then\n",
    "        err = 1\n",
    "        return\n",
    "    endif\n",
    "        \n",
    "    ! smid and tmid are number of pixels between the center pixel\n",
    "    ! and the edge, ie for a 5x5 filter they will be 2.  \n",
    "    smid = smax / 2\n",
    "    tmid = tmax / 2\n",
    "    \n",
    "    CALL OMP_SET_NUM_THREADS(8)\n",
    "    \n",
    "    h = 0\n",
    "    ! Do convolution\n",
    "    ! warning : memory layout is different in fortran\n",
    "    ! warning : array start at 1 in fortran\n",
    "\n",
    "    !$OMP PARALLEL DO DEFAULT(SHARED) COLLAPSE(1) &\n",
    "    !$OMP PRIVATE(v1,v2,w1,w2)\n",
    "    do y = tmid + 1,wmax - tmid\n",
    "        do x = smid + 1,vmax - smid\n",
    "            ! Calculate pixel value for h at (x,y). Sum one component\n",
    "            ! for each pixel (s, t) of the filter g.\n",
    "            \n",
    "            !value = 0\n",
    "            !do t = 1, tmax\n",
    "            !    do s = 1, smax\n",
    "            !        v = x - smid + s -1\n",
    "            !        w = y - tmid + t -1\n",
    "            !        \n",
    "            !        value = value + g(s, t) * f(v, w)\n",
    "            !    enddo\n",
    "            !enddo\n",
    "            \n",
    "            v1 = x - smid\n",
    "            v2 = v1 + smax\n",
    "            w1 = y - tmid\n",
    "            w2 = w1 + tmax\n",
    "            h(x, y) = sum(g(1:smax,1:tmax) * f(v1:v2,w1:w2))\n",
    "        enddo\n",
    "    enddo\n",
    "    !$OMP END PARALLEL DO\n",
    "    return\n",
    "    end subroutine convolve_fortran\n",
    "    end module fortranmodule\n",
    "    \"\"\"\n",
    "\n",
    "with open(\"fortranModule.f90\", 'w') as fortranfile:\n",
    "    for line in fsource:\n",
    "        fortranfile.write(line)\n",
    "\n",
    "import subprocess\n",
    "try:\n",
    "#    data = subprocess.check_output([\"f2py\",\n",
    "    data = subprocess.check_output([\"/home/pythonstudent/.local/bin/f2py\",\n",
    "                                    \"-c\", \"fortranModule.f90\",\n",
    "                                    \"-m\", \"myfortranmodule\",\n",
    "                                    \"--opt='-Ofast -march=native -fopenmp -fopt-info'\", \"--noarch\", \"-lgomp\",\n",
    "                                    #\"--opt='-Ofast -xHost -qopenmp '\", \"--noarch\", \"-liomp5\",\n",
    "                                    #\"--debug-capi\", \"--debug\",\n",
    "                                    \"-DF2PY_REPORT_ON_ARRAY_COPY=1\"\n",
    "                                   ]).decode('utf-8')\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(e.output.decode('utf-8'))\n",
    "else:\n",
    "    #print(data)\n",
    "    print(\"compilation OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from myfortranmodule import fortranmodule\n",
    "\n",
    "_ffunction1 = fortranmodule.function1\n",
    "ffunction2 = fortranmodule.function2\n",
    "ffunction2.__name__ = \"ffunction2\"\n",
    "convolve_fortran = fortranmodule.convolve_fortran\n",
    "\n",
    "def ffunction1(a ,b):\n",
    "    return _ffunction1(a, b).astype(bool)\n",
    "\n",
    "def fortran_convolve(f, g):\n",
    "    h, err = convolve_fortran(f, g)\n",
    "    if err:\n",
    "        print(err)\n",
    "        raise ValueError(\"FORTRAN ERROR ! (Probably : Only odd dimensions on filter supported)\")\n",
    "    return h\n",
    "\n",
    "def fortran_setup(f, g):\n",
    "    # memory ordering for fortran\n",
    "    ft = np.asfortranarray(f.copy())\n",
    "    gt = np.asfortranarray(g.copy())\n",
    "    return ft, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### The produced binary is simple enough to be decompiled\n",
    "import subprocess\n",
    "data = subprocess.check_output([\"gdb\", \"-batch\",\n",
    "                                \"-ex\", \"file myfortranmodule.cpython-35m-x86_64-linux-gnu.so\",\n",
    "                                \"-ex\", \"disassemble /s __fortranmodule_MOD_function1\"]).decode('utf-8')\n",
    "                                #\"-ex\", \"disassemble /m fortranmodule_mp_function1_\"]).decode('utf-8')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check(ffunction1, (a, b), ref=ref1)\n",
    "_ = check(ffunction2, (a, b), ref=ref2)\n",
    "print()\n",
    "_ = check(fortran_convolve, (small_f, g), ref=ref_small_convolve, setup=fortran_setup)\n",
    "_ = check(fortran_convolve, (large_f, g), ref=ref_large_convolve, setup=fortran_setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to test all of these implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Easy cases\")\n",
    "a = np.arange(1,1e6)\n",
    "b = np.arange(1,1e6)\n",
    "\n",
    "print(\"With numpy\")\n",
    "ref1 = check(pyfunction1, (a, b))\n",
    "ref2 = check(pyfunction2, (a, b))\n",
    "_ = check(pyfunction2_bis, (a, b), ref=ref2)\n",
    "print()\n",
    "print(\"With numexpr\")\n",
    "_ = check(ne_function1, (a, b), ref=ref1)\n",
    "_ = check(ne_function2, (a, b), ref=ref2)\n",
    "print()\n",
    "print(\"With numba\")\n",
    "_ = check(nb_function1, (a, b), ref=ref1)\n",
    "_ = check(nb_function2, (a, b), ref=ref2)\n",
    "print()\n",
    "print(\"With cython\")\n",
    "_ = check(cython_function1, (a, b), ref=ref1)\n",
    "_ = check(cython_function2, (a, b), ref=ref2)\n",
    "print()\n",
    "print(\"With fortran\")\n",
    "_ = check(ffunction1, (a, b), ref=ref1)\n",
    "_ = check(ffunction2, (a, b), ref=ref2)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Convolution: small case\")\n",
    "n = 4\n",
    "s = 2 * n + 1\n",
    "g = np.arange(s ** 2, dtype=np.int).reshape((s, s))\n",
    "\n",
    "N = 200\n",
    "small_f = np.arange(N * N, dtype=np.int).reshape((N, N))\n",
    "\n",
    "print(\"With numpy\")\n",
    "ref_small_convolve = check(convolve_python, (small_f, g))\n",
    "print()\n",
    "print(\"With scipy\")\n",
    "_ = check(scipy_convolve, (small_f, g), ref=ref_small_convolve, setup=scipy_setup)\n",
    "print()\n",
    "print(\"With numba\")\n",
    "_ = check(convolve_numba, (small_f, g), ref=ref_small_convolve)\n",
    "print(\"With numba and stencil\")\n",
    "_ = check(convolve_numba1, (small_f, g), ref=ref_small_convolve)\n",
    "print()\n",
    "print(\"With cython\")\n",
    "_ = check(cython_convolve, (small_f, g), ref=ref_small_convolve)\n",
    "print()\n",
    "print(\"With fortran\")\n",
    "_ = check(fortran_convolve, (small_f, g), ref=ref_small_convolve, setup=fortran_setup)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convolution: large case\")\n",
    "n = 4\n",
    "s = 2 * n + 1\n",
    "g = np.arange(s ** 2, dtype=np.int).reshape((s, s))\n",
    "\n",
    "N = 2000\n",
    "large_f = np.arange(N * N, dtype=np.int).reshape((N, N))\n",
    "\n",
    "print(\"With scipy\")\n",
    "ref_large_convolve = check(scipy_convolve, (large_f, g), setup=scipy_setup)\n",
    "print()\n",
    "print(\"With numba\")\n",
    "_ = check(convolve_numba, (large_f, g), ref=ref_large_convolve)\n",
    "print(\"With numba and stencil\")\n",
    "_ = check(convolve_numba1, (large_f, g), ref=ref_large_convolve)\n",
    "print()\n",
    "print(\"With cython\")\n",
    "_ = check(cython_convolve, (large_f, g), ref=ref_large_convolve)\n",
    "print()\n",
    "print(\"With fortran\")\n",
    "_ = check(fortran_convolve, (large_f, g), ref=ref_large_convolve, setup=fortran_setup)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parallelism\n",
    "  - cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CUDA DOESN'T WORK ON THE VIRTUAL MACHINE\n",
    "YOU ARE WELCOME TO TRY THIS ON YOU OWN COMPUTER\n",
    "\"\"\"\n",
    "from string import Template\n",
    "\n",
    "cuda_src_template = Template(\"\"\"\n",
    "// Cuda splitting\n",
    "#define MTB ${max_threads_per_block}\n",
    "#define MBP ${max_blocks_per_grid}\n",
    "\n",
    "// Array size\n",
    "#define fx ${fx}\n",
    "#define fy ${fy}\n",
    "#define gx ${gx}\n",
    "#define gy ${gy}\n",
    "\n",
    "// Macro for converting subscripts to linear index:\n",
    "#define f_INDEX(i, j) (i) * (fy) + (j)\n",
    "\n",
    "// Macro for converting subscripts to linear index:\n",
    "#define g_INDEX(i, j) (i) * (gy) + (j)\n",
    "\n",
    "__global__ void convolve_cuda(long *f, long *g, long *h) {\n",
    "\n",
    "    unsigned int idx = blockIdx.y * MTB * MBP + blockIdx.x * MTB + threadIdx.x;\n",
    "\n",
    "    // Convert the linear index to subscripts:\n",
    "    unsigned int i = idx / fy;\n",
    "    unsigned int j = idx % fy;\n",
    "\n",
    "    long smax = gx;\n",
    "    long tmax = gy;\n",
    "\n",
    "    long smid = smax / 2;\n",
    "    long tmid = tmax / 2;\n",
    "\n",
    "    if (smid <= i && i < fx - smid) {\n",
    "    if (tmid <= j && j < fy - tmid) {\n",
    "\n",
    "        h[f_INDEX(i, j)] = 0.;\n",
    "        \n",
    "        for (long s = 0; s < smax; s++)\n",
    "            for (long t = 0; t < tmax; t++)\n",
    "                h[f_INDEX(i, j)] += g[g_INDEX(s, t)] * f[f_INDEX(i + s - smid, j + t - tmid)];\n",
    "    \n",
    "    }\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CUDA DOESN'T WORK ON THE VIRTUAL MACHINE\n",
    "YOU ARE WELCOME TO TRY THIS ON YOU OWN COMPUTER\n",
    "\"\"\"\n",
    "import skcuda.misc as misc\n",
    "import pycuda.autoinit\n",
    "device = pycuda.autoinit.device\n",
    "max_threads_per_block, _, max_grid_dim = misc.get_dev_attrs(device)\n",
    "max_blocks_per_grid = max(max_grid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CUDA DOESN'T WORK ON THE VIRTUAL MACHINE\n",
    "YOU ARE WELCOME TO TRY THIS ON YOU OWN COMPUTER\n",
    "\"\"\"\n",
    "from functools import partial\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "cuda_src = cuda_src_template.substitute(max_threads_per_block=max_threads_per_block,\n",
    "                                        max_blocks_per_grid=max_blocks_per_grid,\n",
    "                                        fx=large_f.shape[0], fy=large_f.shape[1],\n",
    "                                        gx=g.shape[0], gy=g.shape[1]\n",
    "                                       )\n",
    "cuda_module = SourceModule(cuda_src, options= [\"-O3\", \"-use_fast_math\", \"-default-stream=per-thread\"])\n",
    "print(\"Compilation OK\")\n",
    "\n",
    "__convolve_cuda = cuda_module.get_function('convolve_cuda')\n",
    "\n",
    "block_dim, grid_dim = misc.select_block_grid_sizes(device, f.shape)\n",
    "_convolve_cuda = partial(__convolve_cuda,\n",
    "                         block=block_dim,\n",
    "                         grid=grid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CUDA DOESN'T WORK ON THE VIRTUAL MACHINE\n",
    "YOU ARE WELCOME TO TRY THIS ON YOU OWN COMPUTER\n",
    "\"\"\"\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "def convolve_cuda(f, g):\n",
    "    f_gpu = gpuarray.to_gpu(f)\n",
    "    g_gpu = gpuarray.to_gpu(g)\n",
    "    h_gpu = gpuarray.zeros_like(f_gpu)\n",
    "    _convolve_cuda(f_gpu, g_gpu, h_gpu)\n",
    "    return h_gpu.get()\n",
    "\n",
    "def convolve_cuda2(f_gpu, g_gpu):\n",
    "    h_gpu = gpuarray.zeros_like(f_gpu)\n",
    "    _convolve_cuda(f_gpu, g_gpu, h_gpu)\n",
    "    return h_gpu.get()\n",
    "\n",
    "def cuda_setup(f, g):\n",
    "    f_gpu = gpuarray.to_gpu(f)\n",
    "    g_gpu = gpuarray.to_gpu(g)\n",
    "    return f_gpu, g_gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CUDA DOESN'T WORK ON THE VIRTUAL MACHINE\n",
    "YOU ARE WELCOME TO TRY THIS ON YOU OWN COMPUTER\n",
    "\"\"\"\n",
    "print(\"Cuda\")\n",
    "check(convolve_cuda, (f, g), ref=ref)\n",
    "print(\"Cuda without comm\")\n",
    "check(convolve_cuda2, (f, g), ref=ref, setup=cuda_setup)\n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- asyncio\n",
    "    - not a real parallelism\n",
    "    - effective for io-bound tasks (web)\n",
    "    - not very interesting here\n",
    "- multithreading\n",
    "    - more parallelism (GIL)\n",
    "    - shared memory\n",
    "- multiprocessing\n",
    "    - real parallelism\n",
    "    - limited to one computer\n",
    "    - two main implementation\n",
    "        - multiprocessing (stdlib) which is flexible\n",
    "        - joblib which is relatively easy to use\n",
    "- mpi (mpi4py)\n",
    "    - real parallelism\n",
    "    - unlimited\n",
    "    - relatively complex to use (same as in C, fortran, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "def heavy_fonction(i):\n",
    "    t = np.random.rand() / 10\n",
    "    time.sleep(t)\n",
    "    return i, t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    tic = time.time()\n",
    "    res = Parallel(n_jobs=-1)(delayed(heavy_fonction)(i) \\\n",
    "                                for i in range(2000))\n",
    "    tac = time.time()\n",
    "    index, times = np.asarray(res).T\n",
    "    print(tac - tic)\n",
    "    print(times.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, RLock\n",
    "\n",
    "N = 2000\n",
    "N_t = 10\n",
    "current = 0\n",
    "nprocs = 8\n",
    "output_list = np.empty(N)\n",
    "\n",
    "lock = RLock()\n",
    "\n",
    "class ThreadJob(Thread):\n",
    "    def run(self):\n",
    "        global current\n",
    "        \"\"\"Code Ã  exÃ©cuter pendant l'exÃ©cution du thread.\"\"\"\n",
    "        while current < N:\n",
    "            \n",
    "            with lock:\n",
    "                position = current\n",
    "                current += N_t\n",
    "            \n",
    "            fin = min(position + N_t + 1, N)\n",
    "            \n",
    "            for i in range(position, fin):\n",
    "                j, t = heavy_fonction(i)\n",
    "                output_list[j] = t\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Threads creation\n",
    "    threads = [ThreadJob() for i in range(nprocs)]\n",
    "\n",
    "    tic = time.time()\n",
    "    # Threads starts\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Waiting that all thread have finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    tac = time.time()\n",
    "\n",
    "\n",
    "    print(tac - tic)\n",
    "    print(output_list.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from queue import Empty\n",
    "\n",
    "def process_job(q,r):\n",
    "    while True:\n",
    "        try:\n",
    "            i = q.get(block=False)\n",
    "            r.put(heavy_fonction(i))\n",
    "        except Empty:\n",
    "            if q.empty():\n",
    "                if q.qsize() == 0:\n",
    "                    break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define an output queue\n",
    "    r = mp.Queue()\n",
    "\n",
    "    # Define an input queue\n",
    "    q = mp.Queue()\n",
    "\n",
    "    for i in range(2000):\n",
    "        q.put(i)\n",
    "\n",
    "    nprocs = 8\n",
    "    # Setup a list of processes that we want to run\n",
    "    processes = [mp.Process(target=process_job, args=(q, r)) for i in range(nprocs)]\n",
    "\n",
    "    tic = time.time()\n",
    "\n",
    "    # Run processes\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "\n",
    "    # Get process results from the output queue\n",
    "    results = np.empty(2000)\n",
    "    for i in range(2000):\n",
    "        j, t = r.get()\n",
    "        results[j] = t\n",
    "\n",
    "    tac = time.time()\n",
    "\n",
    "    # Exit the completed processes\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(tac - tic)\n",
    "    print(results.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "The following code read an image in pgm format (ascii) and store it in a 2D list.  \n",
    "For each pixel of the image a kernel get all neighbors (9 counting the pixel itself) and apply a computation.  \n",
    "Analyse the performance of the code, identify bottleneck and try to optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_description(filename):\n",
    "    \"\"\"\n",
    "    Read the header part of the file\n",
    "    \"\"\"\n",
    "    f = open(filename, 'r')\n",
    "    nline = 0\n",
    "    description = {}\n",
    "    while nline < 3:\n",
    "        line = f.readline()\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        nline += 1\n",
    "        if nline == 1:\n",
    "            description['format'] = line.strip()\n",
    "        elif nline == 2:\n",
    "            description['dimension'] = int(line.split()[1]), int(line.split()[0])\n",
    "        elif nline ==3:\n",
    "            description['deep'] = int(line.strip())\n",
    "    f.close()\n",
    "    return description\n",
    "\n",
    "def get_value(filename, coord):\n",
    "    \"\"\"\n",
    "    Get value at coord in an image in the PGM format\n",
    "    \n",
    "    The main problem here is that the file have a limited width, and the values are wrapped\n",
    "    Thus, the value at coord 12,32 might be in the 24,6 in the file\n",
    "    \"\"\"\n",
    "    description = get_description(filename)\n",
    "    xdim, ydim = description['dimension']\n",
    "    i = coord[0]\n",
    "    j = coord[1]\n",
    "    f = open(filename, 'r', encoding='utf-8')\n",
    "    nline = 0\n",
    "    while nline < 3:\n",
    "        line = f.readline()\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        nline += 1\n",
    "    #here we are at coordinate (0,0)\n",
    "    icur, jcur = 0,0\n",
    "    test = True\n",
    "    while(test):\n",
    "        values = f.readline().split()\n",
    "        nvalues = len(values)\n",
    "        if (icur == i):\n",
    "            if (jcur + nvalues > j):\n",
    "                jvalues = j - jcur\n",
    "                value = values[jvalues]\n",
    "                test=False\n",
    "            else:\n",
    "                jcur += nvalues\n",
    "        else:\n",
    "            jcur += nvalues\n",
    "        if (jcur >= ydim):\n",
    "            icur += jcur // ydim\n",
    "            jcur = jcur % ydim\n",
    "    f.close()\n",
    "    return int(value)\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read an image in the PGM format\n",
    "    \"\"\"\n",
    "    description=get_description(filename)\n",
    "    values = []\n",
    "    for i in range(description['dimension'][0]):\n",
    "        values.append([])\n",
    "        for j in range(description['dimension'][1]):\n",
    "            values[i].append(get_value(filename, (i, j)))\n",
    "\n",
    "    return values\n",
    "\n",
    "def get_neighbors(tab, i, j):\n",
    "    neigh = []\n",
    "    for jrange in [-1, 0, 1]:\n",
    "        for irange in [-1, 0, 1]:\n",
    "            neigh.append(tab[i + irange][j + jrange])\n",
    "    return neigh\n",
    "\n",
    "def compute_wtf(neigh):\n",
    "    value = 1.\n",
    "    for i in range(len(neigh)):\n",
    "        value *= math.exp(neigh[i]) ** (1 / len(neigh))\n",
    "    value = math.log(value)\n",
    "        \n",
    "    return float(value)\n",
    "\n",
    "def kernel(tab):\n",
    "    \"\"\"\n",
    "    Apply compute_wtf on each pixel except boundary\n",
    "    \"\"\"\n",
    "    xdim = len(tab)\n",
    "    ydim = len(tab[0])\n",
    "    result = []\n",
    "    #1st line\n",
    "    result.append([0])\n",
    "    for jrange in range(1, ydim):\n",
    "        result[0].append(0)\n",
    "    for irange in range(1, xdim - 1):\n",
    "        #1st column\n",
    "        result.append([0])\n",
    "        for jrange in range(1, ydim - 1):\n",
    "            neigh = get_neighbors(tab, irange, jrange)\n",
    "            result[irange].append(compute_wtf(neigh))\n",
    "        #last colum\n",
    "        result[irange].append(0)\n",
    "    #last line\n",
    "    result.append([])\n",
    "    for jrange in range(ydim):\n",
    "        result[xdim - 1].append(0)\n",
    "    return result\n",
    "\n",
    "def job(data):\n",
    "    \"\"\"\n",
    "    Apply kernel of each image\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for image in data:\n",
    "        results.append(kernel(image))\n",
    "    return results\n",
    "\n",
    "def init(files):\n",
    "    \"\"\"\n",
    "    Read all files\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(read_file(file))\n",
    "        \n",
    "    return data  \n",
    "\n",
    "def plot(data):\n",
    "    nimages = len(data)\n",
    "    \n",
    "    if nimages > 1:\n",
    "        fig, axes = plt.subplots(nimages, 1)\n",
    "        for image, ax in zip(data, axes):\n",
    "            ax.imshow(image)\n",
    "    else:\n",
    "        plt.figure()\n",
    "        plt.imshow(data[0])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "files=[\"data/test.pgm\"]\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Reading Files\")\n",
    "    data = init(files)\n",
    "\n",
    "    print(\"Computing\")\n",
    "    result = job(data)\n",
    "\n",
    "    plot(data)\n",
    "    plot(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to optimize this code.  \n",
    "You can apply your code on the following images :\n",
    "- data/test.pgm\n",
    "- data/test32.pgm\n",
    "- data/brain_604.ascii.pgm\n",
    "- data/apollonian_gasket.ascii.pgm\n",
    "- data/dla.ascii.pgm\n",
    "\n",
    "For reference, the timing on my computer are :  \n",
    "For data/test.pgm\n",
    "\n",
    "On my computer :\n",
    "```\n",
    "Reading Files\n",
    "6.67 ms Â± 262 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n",
    "Computing\n",
    "503 Âµs Â± 5.41 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n",
    "```\n",
    "\n",
    "My solution\n",
    "```\n",
    "Reading Files\n",
    "83.9 Âµs Â± 3.9 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)\n",
    "Computing\n",
    "255 Âµs Â± 19.4 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n",
    "```\n",
    "\n",
    "And, the bigger the image, the bigger the gain !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#hints\">Hints</button>\n",
    "<div id=\"hints\" class=\"collapse\">\n",
    "    \n",
    "Part 1\n",
    "- Open input file only once\n",
    "- Avoid appending data\n",
    "- Use numpy array for data storage\n",
    "- What is really doing the compute_wtf function ?\n",
    "\n",
    "Part 2\n",
    "- compile the compute part\n",
    "\n",
    "Part 3\n",
    "- parallelize the work on each image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#optim1\">Solution : Part 1</button>\n",
    "<div id=\"optim1\" class=\"collapse\">\n",
    "```python\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def get_description(file):\n",
    "    \"\"\"\n",
    "    Read the header part of the file\n",
    "\n",
    "    And leave the file at the end of header (start of values)\n",
    "    \"\"\"\n",
    "    # return to begining\n",
    "    file.seek(0)\n",
    "    nline = 0\n",
    "    description = {}\n",
    "    while nline < 3:\n",
    "        line = file.readline()\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        nline += 1\n",
    "        if nline == 1:\n",
    "            description['format'] = line.strip()\n",
    "        elif nline == 2:\n",
    "            description['dimension'] = int(line.split()[1]), int(line.split()[0])\n",
    "        elif nline == 3:\n",
    "            description['deep'] = int(line.strip())\n",
    "    return description\n",
    "\n",
    "def read_values(file, description):\n",
    "    \"\"\"\n",
    "    Read all the values directly\n",
    "    \"\"\"\n",
    "    # pre-allocate the array\n",
    "    nx, ny = description['dimension']\n",
    "    values = np.empty((nx * ny))\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        vals = line.split()\n",
    "        nvals = len(vals)\n",
    "        values[i:i + nvals] = [int(v) for v in vals]\n",
    "        i += nvals\n",
    "    return values.reshape((nx, ny))\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read an image in the PGM format\n",
    "    \"\"\"\n",
    "    # open the file once\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as file:\n",
    "\n",
    "        # read the header part\n",
    "        description = get_description(file)\n",
    "\n",
    "        # read the values\n",
    "        values = read_values(file, description)\n",
    "    return values\n",
    "\n",
    "\n",
    "def init(files):\n",
    "    \"\"\"\n",
    "    Read all files\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(read_file(file))\n",
    "\n",
    "    return data\n",
    "    \n",
    "#prepare result array\n",
    "result = deepcopy(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#optim2\">Solution : Part 2</button>\n",
    "<div id=\"optim2\" class=\"collapse\">\n",
    "\n",
    "In the python part :\n",
    "-----------------------\n",
    "```python\n",
    "def kernel(i):\n",
    "    \"\"\"\n",
    "    Apply compute_wtf on each pixel except boundary\n",
    "    \"\"\"\n",
    "    global data, result, t_omp\n",
    "    result[i] = ckernel(data[i], nt_omp)\n",
    "```\n",
    "\n",
    "In a new cell :\n",
    "-----------------\n",
    "``` %load_ext Cython ```\n",
    " \n",
    "In a new cell :\n",
    "-----------------\n",
    "```cython\n",
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp\n",
    "## --compile-args=-DCYTHON_TRACE_NOGIL=1 --compile-args=-DCYTHON_TRACE=1 \n",
    "# cython: language_level=3\n",
    "# cython: boundscheck=False\n",
    "# cython: wraparound=False\n",
    "# cython: initializedcheck=False\n",
    "# cython: binding=True\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from cython.parallel cimport parallel, prange\n",
    "\n",
    "def ckernel(double[:,::1] data,long nt):\n",
    "    cdef long n = data.shape[0]\n",
    "    cdef long m = data.shape[1]\n",
    "\n",
    "    cdef double[:,::1] res = np.zeros([n, m], dtype=np.double)\n",
    "    cdef double value\n",
    "\n",
    "    cdef long i, j, s, t\n",
    "    with nogil, parallel(num_threads=nt):\n",
    "        for i in prange(1, n - 1):\n",
    "            for j in range(1, m - 1):\n",
    "                value = 0\n",
    "                for s in range(-1, 2):\n",
    "                    for t in range(-1, 2):\n",
    "                        value += data[i + s, j + t]\n",
    "                res[i, j] += value / 9\n",
    "    return res\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#optim3\">Solution : Part 3</button>\n",
    "<div id=\"optim3\" class=\"collapse\">\n",
    "```python\n",
    "from threading import Thread, RLock\n",
    "import os\n",
    "\n",
    "nprocs = os.cpu_count()\n",
    "nt_omp = nprocs // 2\n",
    "nt_job =nprocs - nt_omp\n",
    "\n",
    "result = []\n",
    "data = []\n",
    "\n",
    "current = 0\n",
    "\n",
    "verrou = RLock()\n",
    "\n",
    "class ThreadJob(Thread):\n",
    "    def run(self):\n",
    "        global current,verrou\n",
    "        \"\"\"Code Ã  exÃ©cuter pendant l'exÃ©cution du thread.\"\"\"\n",
    "        while current < len(data):\n",
    "\n",
    "            with verrou:\n",
    "                position = current\n",
    "                current += 1\n",
    "\n",
    "            kernel(position)\n",
    "\n",
    "def job(data):\n",
    "    \"\"\"\n",
    "    Apply kernel on each image\n",
    "    \"\"\"\n",
    "    global current\n",
    "\n",
    "    current = 0\n",
    "    # CrÃ©ation des threads\n",
    "    threads = [ThreadJob() for i in range(nt_job)]\n",
    "\n",
    "    # Lancement des threads\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Attend que les threads se terminent\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "#sort data bigger first for better equilibrium\n",
    "data = sorted(data, key=np.size, reverse=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#optimfull\">Full solution</button>\n",
    "<div id=\"optimfull\" class=\"collapse\">\n",
    "Cell 1 :\n",
    "--------\n",
    "```%load_ext Cython```\n",
    "    \n",
    "Cell 2 :\n",
    "--------\n",
    "```cython\n",
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp\n",
    "## --compile-args=-DCYTHON_TRACE_NOGIL=1 --compile-args=-DCYTHON_TRACE=1 \n",
    "# cython: language_level=3\n",
    "# cython: boundscheck=False\n",
    "# cython: wraparound=False\n",
    "# cython: initializedcheck=False\n",
    "# cython: binding=True\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from cython.parallel cimport parallel, prange\n",
    "\n",
    "def ckernel(double[:,::1] data, long nt):\n",
    "    cdef long n = data.shape[0]\n",
    "    cdef long m = data.shape[1]\n",
    "    \n",
    "    cdef double[:,::1] res = np.zeros([n, m], dtype=np.double)\n",
    "    cdef double value\n",
    "    \n",
    "    cdef long i, j, s, t\n",
    "    with nogil, parallel(num_threads=nt):\n",
    "        for i in prange(1, n - 1):\n",
    "            for j in range(1, m - 1):\n",
    "                value = 0\n",
    "                for s in range(-1, 2):\n",
    "                    for t in range(-1, 2):\n",
    "                        value += data[i + s, j + t]\n",
    "                res[i, j] += value / 9\n",
    "    return res\n",
    "```\n",
    "\n",
    "Cell 3 :\n",
    "--------\n",
    "```python\n",
    "%matplotlib notebook \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from threading import Thread, RLock\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "nprocs = os.cpu_count()\n",
    "nt_omp = nprocs // 2\n",
    "nt_job =nprocs - nt_omp\n",
    "\n",
    "result = []\n",
    "data = []\n",
    "\n",
    "current = 0\n",
    "\n",
    "verrou = RLock()\n",
    "\n",
    "class ThreadJob(Thread):\n",
    "    def run(self):\n",
    "        global current,verrou\n",
    "        \"\"\"Code Ã  exÃ©cuter pendant l'exÃ©cution du thread.\"\"\"\n",
    "        while current < len(data):\n",
    "            \n",
    "            with verrou:\n",
    "                position = current\n",
    "                current += 1\n",
    "            \n",
    "            kernel(position)\n",
    "\n",
    "def get_description(file):\n",
    "    \"\"\"\n",
    "    Read the header part of the file\n",
    "    \n",
    "    And leave the file at the end of header (start of values)\n",
    "    \"\"\"\n",
    "    # return to begining\n",
    "    file.seek(0)\n",
    "    nline = 0\n",
    "    description = {}\n",
    "    while nline < 3:\n",
    "        line = file.readline()\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        nline += 1\n",
    "        if nline == 1:\n",
    "            description['format']=line.strip()\n",
    "        elif nline == 2:\n",
    "            description['dimension']=int(line.split()[1]), int(line.split()[0])\n",
    "        elif nline == 3:\n",
    "            description['deep']=int(line.strip())\n",
    "    return description\n",
    "        \n",
    "def read_values(file, description):\n",
    "    \"\"\"\n",
    "    Read all the values directly\n",
    "    \"\"\"\n",
    "    # pre-allocate the array\n",
    "    nx, ny = description['dimension']\n",
    "    values = np.empty((nx * ny))\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        vals = line.split()\n",
    "        nvals = len(vals)\n",
    "        values[i:i + nvals] = [int(v) for v in vals]\n",
    "        i += nvals\n",
    "    return values.reshape((nx, ny))\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read an image in the PGM format\n",
    "    \"\"\"\n",
    "    # open the file once\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as file:\n",
    "\n",
    "        # read the header part\n",
    "        description = get_description(file)\n",
    "\n",
    "        # read the values\n",
    "        values = read_values(file, description)\n",
    "    return values\n",
    "\n",
    "def kernel(i):\n",
    "    \"\"\"\n",
    "    Apply compute_wtf on each pixel except boundary\n",
    "    \"\"\"\n",
    "    global data, result, t_omp\n",
    "    result[i] = ckernel(data[i], nt_omp)\n",
    "\n",
    "def job(data):\n",
    "    \"\"\"\n",
    "    Apply kernel of each image\n",
    "    \"\"\"\n",
    "    global current\n",
    "    \n",
    "    current = 0\n",
    "    # CrÃ©ation des threads\n",
    "    threads = [ThreadJob() for i in range(nt_job)]\n",
    "\n",
    "    # Lancement des threads\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Attend que les threads se terminent\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "def init(files):\n",
    "    \"\"\"\n",
    "    Read all files\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(read_file(file))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot(data):\n",
    "    nimages = len(data)\n",
    "    if nimages > 1:\n",
    "        fig, axes = plt.subplots(nimages, 1)\n",
    "        for image, ax in zip(data, axes):\n",
    "            ax.imshow(image)\n",
    "    else:\n",
    "        plt.figure()\n",
    "        plt.imshow(data[0])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "files = [\"data/test.pgm\",\n",
    "         \"data/test32.pgm\",\n",
    "         \"data/brain_604.ascii.pgm\",\n",
    "         \"data/apollonian_gasket.ascii.pgm\",\n",
    "         \"data/dla.ascii.pgm\",\n",
    "        ]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = init(files)\n",
    "\n",
    "    #sort data bigger first for better equilibrium\n",
    "    data = sorted(data, key=np.size, reverse=True)\n",
    "\n",
    "    #prepare result array\n",
    "    result = deepcopy(data)\n",
    "\n",
    "    #plot(data)\n",
    "    plot(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
